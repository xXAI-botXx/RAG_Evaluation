{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8f66db6e",
      "metadata": {
        "id": "8f66db6e"
      },
      "source": [
        "# RAG Evaluation with [RAGBench Benchmark](https://huggingface.co/datasets/galileo-ai/ragbench)\n",
        "\n",
        "A big dataset to evaluate your model with some evaluation scripts but no direct support for new custom model integrations. Therefore: No registration, installation (only HuggingFace) required.\n",
        "\n",
        "Used for evaluation of:\n",
        "- Hallucination Detection\n",
        "- Context Relevance Detection\n",
        "- Context Utilization Detection\n",
        "\n",
        "<br><br>\n",
        "\n",
        "- [Python Env](#python-env)\n",
        "- [Example RAG Model](#example-rag-model)\n",
        "  - Retriever: Embedding + Indexing (Database) (+ example data)\n",
        "  - Reranker (we don't use one)\n",
        "  - Generator: Tokenizer + LLM\n",
        "- [Evaluation with RAGBench](#evaluation-with-ragbench)\n",
        "  - 1. Load Datasets\n",
        "  - 2. Evaluate your model\n",
        "\n",
        "<br><br>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0428195",
      "metadata": {},
      "source": [
        "### Python Env\n",
        "\n",
        "Install Repository:\n",
        "```bash\n",
        "git clone https://github.com/rungalileo/ragbench.git ./ragbench\n",
        "```\n",
        "\n",
        "<br><br>\n",
        "\n",
        "Install using Anaconda-Bash:\n",
        "```bash\n",
        "FIXME -> see bergen evaluation ipynb\n",
        "-> make a own env\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f509379",
      "metadata": {},
      "source": [
        "### System Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7affa27",
      "metadata": {},
      "outputs": [],
      "source": [
        "import prime_printer as prime\n",
        "print(prime.get_hardware())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z-CJwn31TDil",
      "metadata": {
        "id": "z-CJwn31TDil"
      },
      "source": [
        "### Example RAG Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wGAmEayKTPSe",
      "metadata": {
        "id": "wGAmEayKTPSe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
        "import faiss\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u4Z2il9VTP-L",
      "metadata": {
        "id": "u4Z2il9VTP-L"
      },
      "outputs": [],
      "source": [
        "embedding_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "embedding_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "embedding_model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\", dtype=torch.float16)\n",
        "embedding_model.resize_token_embeddings(len(embedding_tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "305948a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(\n",
        "    embedding_tokenizer,\n",
        "    input_size=(1, 1)        # batch size, sequence length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c1ffcfa",
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(\n",
        "    embedding_model,\n",
        "    input_size=(1, 1)        # batch size, sequence length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kVfIVA-OTV2T",
      "metadata": {
        "id": "kVfIVA-OTV2T"
      },
      "outputs": [],
      "source": [
        "example_documents = [\n",
        "    \"The Eiffel Tower is located in Paris.\",\n",
        "    \"The Pythagorean theorem describes the relationship between the sides of a right triangle.\",\n",
        "    \"The capital of Germany is Berlin.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab44002",
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode(model, tokenizer, texts):\n",
        "    tokens = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**tokens)\n",
        "        embeddings = outputs.last_hidden_state.mean(dim=1)  # CLS Token pooling\n",
        "        # attention_mask = tokens[\"attention_mask\"].unsqueeze(-1)\n",
        "        # embeddings = (outputs.last_hidden_state * attention_mask).sum(dim=1)\n",
        "        # embeddings = embeddings / attention_mask.sum(dim=1)\n",
        "    return embeddings.cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QWkCxhy6TZS0",
      "metadata": {
        "id": "QWkCxhy6TZS0"
      },
      "outputs": [],
      "source": [
        "doc_embeddings = encode(embedding_model, embedding_tokenizer, example_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Gyu2oxxCTzfn",
      "metadata": {
        "id": "Gyu2oxxCTzfn"
      },
      "source": [
        "Build FAISS Index (our \"database\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfdpihG5TxDl",
      "metadata": {
        "id": "dfdpihG5TxDl"
      },
      "outputs": [],
      "source": [
        "dim = doc_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(doc_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gkGXrFoeT8BP",
      "metadata": {
        "id": "gkGXrFoeT8BP"
      },
      "source": [
        "Load a language model (decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6kwAA6cTT8iw",
      "metadata": {
        "id": "6kwAA6cTT8iw"
      },
      "outputs": [],
      "source": [
        "model_name = \"gpt2\"  # \"distilgpt2\"\n",
        "generator_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "generator_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "generator_model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             device_map=\"auto\",\n",
        "                                             dtype=torch.float16)\n",
        "generator_model.resize_token_embeddings(len(generator_tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6127f23",
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(\n",
        "    generator_tokenizer,\n",
        "    input_size=(1, 1)        # batch size, sequence length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "611062be",
      "metadata": {},
      "outputs": [],
      "source": [
        "summary(\n",
        "    generator_model,\n",
        "    input_size=(1, 1)        # batch size, sequence length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32742081",
      "metadata": {},
      "outputs": [],
      "source": [
        "generator_model.device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KihX3WsSUGDD",
      "metadata": {
        "id": "KihX3WsSUGDD"
      },
      "source": [
        "RAG Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BBJ5TWimUIAk",
      "metadata": {
        "id": "BBJ5TWimUIAk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def rag_answer(query, given_passages, k=2):\n",
        "    # Create prompt + docs embedding\n",
        "    embedded_prompt = encode(embedding_model, embedding_tokenizer, [query])[0]\n",
        "    given_passages_embedded = encode(embedding_model, embedding_tokenizer, given_passages)\n",
        "\n",
        "    # Convert embeddings to float32 numpy arrays\n",
        "    prompt_vec = embedded_prompt.astype(np.float32).reshape(1, -1)\n",
        "    passage_vecs = given_passages_embedded.astype(np.float32)\n",
        "\n",
        "    # Build index\n",
        "    dim = passage_vecs.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(passage_vecs)\n",
        "\n",
        "    # Retrieve top-k docs\n",
        "    distances, indices = index.search(prompt_vec, k)\n",
        "    retrieved = [given_passages[i] for i in indices[0]]\n",
        "\n",
        "    # Build the final prompt for generation\n",
        "    context_text = \"\\n\".join(retrieved)\n",
        "    prompt = (\n",
        "        f\"Use the following context to answer the question.\\n\\n\"\n",
        "        f\"Context: {context_text}\\n\\n\"\n",
        "        f\"Question: {query}\\nAnswer:\"\n",
        "    )\n",
        "\n",
        "    # Tokenize final prompt\n",
        "    inputs = generator_tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate\n",
        "    outputs = generator_model.generate(\n",
        "        **inputs,\n",
        "        max_length=200,\n",
        "        do_sample=True,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    # Decode output\n",
        "    answer = generator_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer, retrieved"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-ZcStBgbU722",
      "metadata": {
        "id": "-ZcStBgbU722"
      },
      "source": [
        "Example Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ELwq7C49U-2-",
      "metadata": {
        "id": "ELwq7C49U-2-"
      },
      "outputs": [],
      "source": [
        "answer, retrieved_docs = rag_answer(\"Where is the Eiffel Tower located?\", example_documents, k=2)\n",
        "print(f\"Retrieved Docs: {retrieved_docs}\")\n",
        "print(f\"\\nRAG Answer:\\n'{answer}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xeDggQRSVM-P",
      "metadata": {
        "id": "xeDggQRSVM-P"
      },
      "source": [
        "### **Evaluation with RAGBench**\n",
        "\n",
        "Witht he given models it is easy:\n",
        "```bash\n",
        "python run_inference.py --dataset msmarco --model trulens --output results\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "877cf20a",
      "metadata": {},
      "source": [
        "1. Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5852e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# load the full ragbench dataset delucionqa\n",
        "ragbench = {}\n",
        "columns = set()\n",
        "for dataset in ['covidqa', 'cuad', 'delusionqa', 'emanual', 'expertqa', 'finqa', 'hagrid', 'hotpotqa', 'msmarco', 'pubmedqa', 'tatqa', 'techqa']:\n",
        "  ragbench[dataset] = load_dataset(\"rungalileo/ragbench\", dataset)\n",
        "  print(f\"Loaded '{dataset}' dataset from RAGBench\")\n",
        "  columns = columns.union(set(ragbench[dataset]['test'].keys()))\n",
        "print(f\"Columns in ragbench datasets: {columns}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "008fa747",
      "metadata": {},
      "source": [
        "2. Calculate scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb064eb8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path += [\"./ragbench/ragbench\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55025374",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.metrics import faithfulness, answer_relevancy, context_relevancy\n",
        "\n",
        "def evaluate_rag_output(question, answer, contexts):\n",
        "    data = {\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"contexts\": contexts,\n",
        "    }\n",
        "\n",
        "    adherence = faithfulness(data)\n",
        "    relevance = context_relevancy(data)\n",
        "    utilization = answer_relevancy(data)\n",
        "\n",
        "    return float(adherence), float(relevance), float(utilization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d074f94d",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {}\n",
        "for dataset_name, dataset in ragbench.items():\n",
        "    print(f\"Evaluating on {dataset_name}...\")\n",
        "    results[dataset_name] = []\n",
        "    for sample in dataset['test']:\n",
        "        question = sample['question']\n",
        "        # is there also context / documents given? FIXME\n",
        "        ground_truth = sample.get('answers', {}).get('text', [''])[0]  # Adjust based on dataset structure\n",
        "        \n",
        "        given_passages = sample.get('documents', [])\n",
        "        rag_response, contexts = rag_answer(question, given_passages)\n",
        "\n",
        "        adherence, relevance, utilization = evaluate_rag_output(question, answer, contexts)\n",
        "        \n",
        "        results[dataset_name] += [{\n",
        "            'question': question,\n",
        "            'ground_truth': ground_truth,\n",
        "            'rag_response': rag_response,\n",
        "            \"pred_adherence\": adherence,\n",
        "            \"pred_context_relevance\": relevance,\n",
        "            \"pred_context_utilization\": utilization,\n",
        "            \"supported\": sample[\"supported\"],\n",
        "            \"relevance\": sample[\"relevance\"],\n",
        "            \"utilization\": sample[\"utilization\"],\n",
        "        }]\n",
        "\n",
        "    print(f\"Completed evaluation on {dataset_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf6219e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "eval_datasets = []\n",
        "for result_dataset in results.values():\n",
        "    eval_datasets += [Dataset.from_list(result_dataset) ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce55fe95",
      "metadata": {},
      "source": [
        "3. Evaluate your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e23416f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from evaluation import calculate_metrics\n",
        "\n",
        "all_metrices = []\n",
        "for annotated in eval_datasets:\n",
        "    metrics = calculate_metrics(\n",
        "        annotated,\n",
        "        pred_adherence=\"pred_adherence\",\n",
        "        pred_context_releavance=\"pred_context_relevance\",\n",
        "        pred_context_utilization=\"pred_context_utilization\",\n",
        "        ground_truth_adherence=\"supported\", \n",
        "        ground_truth_context_relevance=\"relevance\",\n",
        "        ground_truth_context_utilization=\"utilization\")\n",
        "    all_metrices += [metrics]\n",
        "\n",
        "all_metrices"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
